# -------------------------------------------------------
# ‚úÖ Compare Results from Multiple Fine-tuned Models
# ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå evaluation_results.csv ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
# -------------------------------------------------------

import os
import pandas as pd

# üîß Path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
RESULT_FILE = "D:/thaisum_keyword/evaluation_results.csv"

# -----------------------------
# 1) ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
# -----------------------------
if not os.path.exists(RESULT_FILE):
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {RESULT_FILE}")
    exit()

# -----------------------------
# 2) ‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
# -----------------------------
df = pd.read_csv(RESULT_FILE)

if df.empty:
    print("‚ùå ‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ß‡πà‡∏≤‡∏á ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
    exit()

# -----------------------------
# 3) ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# -----------------------------
print("\nüìä All Models Results:")
print(df)

# -----------------------------
# 4) ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏° F1-Score
# -----------------------------
best_model = df.loc[df["F1-Score"].idxmax()]

print("\n‚úÖ Best Model (by F1-Score):")
print(best_model)

# -----------------------------
# 5) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô CSV ‡πÉ‡∏´‡∏°‡πà (optional)
# -----------------------------
save_path = os.path.join(os.path.dirname(RESULT_FILE), "hyperparameter_comparison.csv")
df.to_csv(save_path, index=False)

print(f"\nüìÅ Saved comparison table to: {save_path}")
